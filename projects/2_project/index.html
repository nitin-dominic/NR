<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Project 3 | Nitin Rai</title> <meta name="author" content="Nitin Rai"> <meta name="description" content="A project that uses transfer learning technique to count sunflower stands in drone-acquired imagery"> <link rel="stylesheet" href="/NR/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/NR/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/NR/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/NR/assets/img/nrf.svg?021de8303a2543f1b01fc32e747c6959"> <link rel="stylesheet" href="/NR/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://nitin-dominic.github.io/NR/NR/projects/2_project/"> <link rel="stylesheet" href="/NR/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/NR/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/NR/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/NR/"><span class="font-weight-bold">Nitin </span>Rai</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/NR/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/NR/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/NR/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/NR/teaching/">Teaching</a> </li> <li class="nav-item "> <a class="nav-link" href="/NR/bookreads/">BookReads</a> </li> <li class="nav-item "> <a class="nav-link" href="/NR/blog/">Blogs</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Project 3</h1> <p class="post-description">A project that uses transfer learning technique to count sunflower stands in drone-acquired imagery</p> </header> <article> <h1 id="crop-stand-count-automation-using-transfer-learning-in-arcgis-pro">Crop stand count automation using transfer learning in ArcGIS Pro</h1> <h3 id="background">Background</h3> <p>This project was done using various ArcPy packages available within the ArcGIS Pro environment. It was mainly scripted to automate <a href="https://pro.arcgis.com/en/pro-app/latest/tool-reference/image-analyst/train-deep-learning-model.htm" rel="external nofollow noopener" target="_blank">transfer learning</a> workflow in ArcGIS Pro for sunflower stand count automation. This script has been made open-source and is the backbone of the paper published <a href="https://elibrary.asabe.org/abstract.asp?aid=52515" rel="external nofollow noopener" target="_blank">here</a>.</p> <h3 id="prerequisites">Prerequisites:</h3> <ol> <li>RGB orthomosaic imgery.</li> <li>Specify a directory with an empty folder before this scripts starts exporting all the indices (output images) or processed images.</li> <li>Properly installed deep learning packages in ArcGIS Pro environment. Check my <a href="https://nitin-dominic.github.io/NR/blog/2020/ArcGISPro/">blog</a> for further clarification.</li> </ol> <h3 id="limitation-of-this-algorithm">Limitation of this algorithm:</h3> <ol> <li>Demands a strong GPU with a good memory (12 GB recommended!)</li> <li>Algorithm has not been tested on multispectral (MS) aerial imgery. We are not sure of the models could be deployed to locate and count sunflower stand in MS imagery.</li> </ol> <h3 id="code-breakdown">Code breakdown</h3> <p><strong>1. Importing all the required packages</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import arcpy,
from arcpy.ia import *,
    "import os, sys,
    "from arcgis.gis import GIS,
    "from arcgis.learn import export_training_data,
    "from arcgis.learn import prepare_data,
    "from arcgis.learn import YOLOv3,
    "from arcgis.learn import FasterRCNN,
</code></pre></div></div> <p><strong>2. Data loading from the directory</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>RGB_imagery = r"E:\Nitin.Rai\ASABE2021\Dataset\sunflower_Clip_2.tif"
arcpy.env.workspace = RGB_imagery
bands = [Raster(os.path.join(RGB_imagery, b))
         for b in arcpy.ListRasters()]
</code></pre></div></div> <p><strong>3. Preparing the dataset for training task</strong></p> <p>The provided Python code snippet appears to be setting up data preparation for a computer vision task involving image chips. The below code snippet uses <a href="https://www.cvlibs.net/datasets/kitti/" rel="external nofollow noopener" target="_blank">KITTI</a> rectangles dealing with the rectanglular shapes of teh identified objects in the imgery. Caution: Set all these parameters based on your understanding and imagery requirements.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dataset_path = r"C:\Users\Nitin.Rai\Desktop\ImageChipsPASCAL"
class_mapping = None
chip_size = 448
val_split = 0.3
batch_size = 64
transform = False
dataset_type = 'KITTI_rectangles'
prepare = prepare_data(dataset_path, class_mapping, chip_size, val_split, batch_size, transform, dataset_type)
</code></pre></div></div> <p><strong>4. Exporting the image chips for training</strong></p> <p>The provided Python code snippet is using the ExportTrainingDataForDeepLearning tool from the ArcGIS library to prepare training data for deep learning models. This tool is commonly used for creating training datasets for object detection tasks.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>raster_dataset = "D:/ArcGIS Projects/Dataset/SunflowerCropImagery.tif"
output = "D:/ArcGIS Projects/Dataset/OutputFolder2233445566"
training_samples = "D:/ArcGIS Projects/Dataset/CropClassification.shp"
chip_format = "TIFF"
tile_sizeX = "448"
tile_sizeY = "448"
stride_sizeX = "224"
stride_sizeY = "224"
nofeature_tiles = "ONLY_TILES_WITH_FEATURES"
metadeta_format = "PASCAL_VOC_rectangles"
start_index = 0
classvalue_field = "Classvalue"
buffer_radius = 0
input_mask_polygons = ""
rotation_angle = 10
reference_system = "MAP_SPACE"
processing = "PROCESS_ITEMS_SEPARATELY"
blacken = "NO_BLACKEN"
crop_mode = "FIXED_SIZE"

ExportTrainingDataForDeepLearning(raster_dataset, output, training_samples,
                                  chip_format, tile_sizeX, tile_sizeY, stride_sizeX,
                                  stride_sizeY, nofeature_tiles, metadeta_format, start_index, 
                                  classvalue_field, buffer_radius, 
                                  input_mask_polygons, rotation_angle, reference_system,
                                  processing, blacken, crop_mode)
</code></pre></div></div> <p><strong>5. Setting up hyperparameters to train the model(s):</strong></p> <p>The provided Python code snippet is training a deep learning model for object detection using RetinaNet. You can chose from various <a href="https://www.esri.com/en-us/arcgis/deep-learning-models" rel="external nofollow noopener" target="_blank">pre-trained models</a> available within ArcGIS Pro environment.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>start_time = datetime.now()
dataset = r'E:\Nitin.Rai\ASABE2021\Dataset\ImageChips'
output_location = r'E:\Nitin.Rai\SunflowerCropDetection\ModelOutput2\RetinaNetReTrained'
eph = 50
objectDetection_model = "RETINANET"
batch_size = 64
arg = "SCALES '[1,1,0.8]'; RATIOS '[0.5,1,1.5]'; chip_size:416"
lr = 0.001
backbone_model = "RESNET50"
pretrained_model = None
validate = 20
stop_training = "STOP_TRAINING"
freeze = "UNFREEZE_MODEL"
TrainDeepLearningModel(dataset, output_location, eph, objectDetection_model, batch_size, arg, lr, backbone_model,
                       pretrained_model, validate, stop_training, freeze)
end_time = datetime.now()
print("Duration of Training the dataset was: {}" .format(end_time - start_time))
</code></pre></div></div> <h3 id="final-ouput-of-the-aerial-imagery">Final ouput of the aerial imagery</h3> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/NR/assets/img/tl3-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/NR/assets/img/tl3-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/NR/assets/img/tl3-1400.webp"></source> <img src="/NR/assets/img/tl3.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> A screenshot of the aerial imagery after the trained and developed model was deployed for locating and counting purpose. Green represents single stands while red are doubles. </div> <h3 id="credits">Credits:</h3> <ol> <li>Imagery was given by Dr. J. Paulo Flores (Assst. Prof at NDSU)</li> <li>Data processing pipeline, workflow, and automation using Python scripting was developed by Nitin Rai</li> </ol> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2024 Nitin Rai. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>, hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>, and tweaked by Nitin Rai. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/NR/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/NR/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/NR/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/NR/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/NR/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/NR/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>