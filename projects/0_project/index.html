<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Project 1 | Nitin Rai</title> <meta name="author" content="Nitin Rai"> <meta name="description" content="Detection and instance segmentation in aerial videos"> <link rel="stylesheet" href="/NR/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/NR/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/NR/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/NR/assets/img/nrf.svg?021de8303a2543f1b01fc32e747c6959"> <link rel="stylesheet" href="/NR/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://nitin-dominic.github.io/NR/NR/projects/0_project/"> <link rel="stylesheet" href="/NR/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/NR/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/NR/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/NR/"><span class="font-weight-bold">Nitin </span>Rai</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/NR/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/NR/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/NR/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/NR/teaching/">Teaching</a> </li> <li class="nav-item "> <a class="nav-link" href="/NR/bookreads/">BookReads</a> </li> <li class="nav-item "> <a class="nav-link" href="/NR/blog/">Blogs</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Project 1</h1> <p class="post-description">Detection and instance segmentation in aerial videos</p> </header> <article> <h1 id="weedvision-a-single-stage-deep-learning-architecture-to-perform-weed-detection-and-segmentation-using-drone-acquired-images">WeedVision: A single-stage deep learning architecture to perform weed detection and segmentation using drone-acquired images</h1> <p><strong>Rai, Nitin;</strong> Sun, Xin</p> <h3 id="background">Background</h3> <p>Deep learning (DL) inspired models have achieved tremendous success in locating target weed species through bounding-box approach (single-stage models) or pixel-wise semantic segmentation (two-stage models), but not both. Therefore, the goal of this research study was to develop a single-stage DL architecture that not only locate weed presence through bounding-boxes but also achieves pixel-wise instance segmentation on unmanned aerial system (UAS) acquired remote sensing images. Moreover, the developed architecture experiments on integrating a novel C3 and C3x module within its backbone for dense feature extraction, as well as ProtoNet (Prototypical network) in its head component for weed masking. Furthermore, the proposed architecture has been trained on five categories of dataset exported using multiple combinations of various dataset augmentation techniques, namely, C1, C2, C3, C4, and C5, for which multiple metrics were assessed on desktop graphical processing unit (GPU) and a palm-sized edge device (AGX Xavier). Results suggest that category C4, a combination of six data augmentation techniques, outperformed the remaining categories by achieving precision scores of 85.4 % (bounding-boxes) and 82.8 % (masking) on a GPU. Whereas, the same model converted to TorchScript was able to achieve 79.1 % and 77 % bounding-box and masking accuracy on an edge device, respectively. The model developed in this research has two potential applications when integrated with site-specific weed management technologies. First, it enables real-time weed detection, allowing for the immediate identification of weeds for spot-spraying applications. Second, it facilitates instance weed masking, aiding in the estimation of weed growth extent in actual field conditions. Moreover, the developed architecture combines both computer vision applications - detection and instance segmentation – to provide comprehensive information about weed growth, eliminating the need for multiple algorithm. Check some open-access resources <a href="https://github.com/nitin-dominic/WeedVision_A_single_stage_architecture_for_weed_detection_and_instance_segmentation" rel="external nofollow noopener" target="_blank">here</a>.</p> <h3 id="novelvital-aspects-of-this-research-study-are">Novel/vital aspects of this research study are:</h3> <ol> <li>Exploring C3 and C3X modules within the DL architecture for robust feature extraction from i/p images</li> <li>Testing the model on five catrgories of datasets acquired using various combinations of data augmentation techniques</li> <li>Assessing model performance on edge device and real-time tasks.</li> </ol> <h3 id="highlights-of-this-research-work-includes">Highlights of this research work includes:</h3> <ul> <li>Single-stage model that achieves weed detection and segmentation.</li> <li>Integrating C3x module within the backbone for detailed feature extraction.</li> <li>Model trained on C4 category achieved the best detection and segmentation scores of 85.4 % and 82.1 %, respectively.</li> <li>Model with ONNX format gained 1.25x inference speed on an edge device.</li> </ul> <h3 id="extracted-features-from-the-input-images-based-on-the-developed-architecture">Extracted features from the input images based on the developed architecture:</h3> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/NR/assets/img/features-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/NR/assets/img/features-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/NR/assets/img/features-1400.webp"></source> <img src="/NR/assets/img/features.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Extracted features from input images at several levels within the neural network architecture. </div> <h3 id="detected-and-masked-weed-species">Detected and masked weed species:</h3> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/NR/assets/img/WeedVision-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/NR/assets/img/WeedVision-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/NR/assets/img/WeedVision-1400.webp"></source> <img src="/NR/assets/img/WeedVision.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Multiple species of weeds detected and masked using UAS-acquired images in in-field conditions. </div> <h3 id="reference">Reference</h3> <p><strong>Rai, N</strong>., &amp; Sun, X. (2024). WeedVision: A single-stage deep learning architecture to perform weed detection and segmentation using drone-acquired images. <em>Comput. Electron. Agric</em>., 108792. <a href="https://doi.org/10.1016/j.compag.2024.108792" rel="external nofollow noopener" target="_blank">https://doi.org/10.1016/j.compag.2024.108792</a></p> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2024 Nitin Rai. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>, hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>, and tweaked by Nitin Rai. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/NR/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/NR/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/NR/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/NR/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/NR/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/NR/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>